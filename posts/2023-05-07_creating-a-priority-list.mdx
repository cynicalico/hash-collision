---
title: "Baphy Devlog II: Creating a Priority List"
date: '2023-05-07'
---

The event bus works, but needs a way to handle system dependencies. Like the event bus itself, this ended up not being a simple task.

In case you missed it, the [previous devlog](/blog/2023-04-20_creating-an-event-bus) goes over the implementation of the event bus used in Baphy. The PrioList is an additional piece of code that augments the event bus, so this may make more sense why I want this if you've read that first.

### The Problem

If multiple systems are subscribed to receive a certain event, the order in which those systems receive that event may be important. There are two solutions I came up with to deal with this problem:
  
  1. Create multiple, more granular events and use those instead.
  2. Allow systems to declare a *dependency* on another system relative to a specific event.

Option one works within the existing system, and does not require additional code for the event bus. The main downside is that it could lead to extremely granular events, where you may only have a single system subscribed to each event.

Option two means we can keep the number of events lower, which I would personally prefer. The downside is that if not designed carefully, certain events could become very hard to follow through multiple systems. This is a tradeoff I'm willing to make in order to be able to use very general events like "Render", and have that control multiple systems at once.

### The Idea

I'm going to talk about this system in a more general sense, since a priority list is a system that the event bus will *use*, but it will not be a part of the event system itself. If there was some other part of the engine that needed a similar system later, I wanted to keep it generic enough that it would be possible to do that.

PrioList was to function as an ordered list, where each entry in the list had a tag/name. Not using the value directly allows for different entries in the list to have the same value. I had a few requirements I wanted to meet:
  
  1. Items can be added to the list in any order, even if *their dependencies are not yet in the list*
  2. Items can be added at any time, *there is not any point where the order is fully cemented and can't be changed anymore*
  3. When items are added, if they are added in the same order then *the same final order will always occur*

The first requirements is the most important, and is by far the most damning. I did not want to have to reorder things if the initialization order of the modules needed to change, which is when event registration occurs. This requirement also has the side effect that I could not find a single existing algorithm for how to do this.

My initial research found the [C3 linearization algorithm](https://en.wikipedia.org/wiki/C3_linearization), which is used to handle method resolution order in languages that support inheritance. This would be perfect for what I need, except that it requires knowing all systems and their dependencies up front. In fact, anything I could find online required knowing the full system ahead of time, which is very much not what I wanted. This makes sense, as most things treat this as a *graph* problem, as it's elegant to represent and solve that way.

I had to come up with my own solution, and I am frankly not clever enough to do it as a real graph problem, so I decided to just start coding and see where it took me.

### The Method

The final order would be a list of pairs, with a string name, and a value of some template type T. Additionally, to avoid searching the entire list every time a new entry is added, a mapping of names to indices is kept. Finally, two support mappings are maintained to handle the "add in any order" requirement: saved dependencies, and unmet dependencies. This gives us four class members:

```cpp
std::vector<std::pair<std::string, T>> order_{};
std::unordered_map<std::string, std::size_t> idx_{};
std::unordered_map<std::string, std::set<std::string>> saved_deps_{};
std::unordered_map<std::string, std::set<std::string>> unmet_deps_{};
```

There are a lot of `std::unordered_map`s there, and we'll discuss that later. The algorithm works with the following steps:

  1. Check if a name has already been added to the list, if so return.
  2. Check if there are dependencies. If not, set the min index to 0, go to step 7.
  3. Find the min and max indices this item can go between. The *min* is the lowest index that is one place beyond the highest index where a dependent is located. The *max* is the highest index that is one place lower than the lowest index where a dependency is located. While finding these indices, store this name in the `unmet_deps` map for any dependency, `D`, that has not been added yet, so when `D` is added, the max index can be found. 
  4. If the min index is less than the max index, go to step .
  5. Choose the max index of an unmet dependency, and "bubble" it, meaning move it so that it is past the previously found min index. 
  6. Remove that item from the list of unmet dependencies.
  7. Find the new min and max indices, go to step 4.
  8. Insert the new name/value pair at the min index.
  9. Fix the `idxs` mapping for all entries past the newly inserted item.

### Performance Improvements

The method listed remained the same, but the exact details of implementation have changed quite a lot from V1 to V7. One thing you may be aware of already is that `std::unordered_map` has quite bad cache complexity. This kills the performance of the algorithm. 

Using the same idea as the event bus for using the payload types as keys, it is possible to simply assign every name an integer. These names can be assigned in order starting from 0, so they can be used as indices to a vector rather than using an actual hash map. Additionally, the names and values were separated into different vectors to try and maintain better cache locality while iterating. There are now 7 class members to keep track of state:

```cpp
std::unordered_map<std::string, std::size_t> s_to_id_{};
std::vector<std::string> id_to_s_{};

std::vector<std::size_t> order_{};
std::vector<T> vals_{};
std::vector<std::size_t> idx_{};
std::vector<std::set<std::size_t>> saved_deps_{};
std::vector<std::set<std::size_t>> unmet_deps_{};
```

I said there no hash maps but I lied, there is still a hash map to convert names to ids, but this is only called at the very beginning of an `add` call, so the cost is minimal.

### Benchmarks

There were 7 total versions that I went through. V1 â†’ V2 is by far the most drastic improvement, and corresponds to the structure mentioned with the list of steps moving to the ID based approach. This was over an order of magnitude faster. V3-V6 are small improvements, or just failed experiments that did not make any difference. V7 is the same as V1, but with `std::unordered_map` replaced with `absl::flat_hash_map` just to see if the performance would notably improve (spoiler, it did not).

The benchmark was performed by generating a list of `N` items to add to the list, sorting it, then making each entry in the list depend on the previous two entries. The list was shuffled, then added to each variant in the same shuffled order, and the final order was compared to the expected order to verify correctness.

The code for generating the dummy data:

```cpp
for (auto N = 500, row = 1; N <= 5'000; N += 500, row++) {
        std::vector<std::string> items{};
        std::unordered_map<std::string, std::set<std::string>> deps_s{};
        std::unordered_map<std::string, std::vector<std::string>> deps_v{};

        for (auto i = 0; i < N; ++i) {
            std::string s(10, 0);
            std::generate_n(s.begin(), 10, []() { return baphy::get<char>(65, 90); });
            items.emplace_back(s);
        }
        std::ranges::sort(items);

        std::string check_string = "[";
        for (const auto &[i, e]: baphy::enumerate(items))
            check_string += fmt::format("{}{}", i != 0 ? ", " : "", e);
        check_string += "]";

        deps_s[items[1]] = {items[0]};
        deps_v[items[1]] = {items[0]};
        deps_s[items[2]] = {items[1], items[0]};
        deps_v[items[2]] = {items[1], items[0]};
        for (std::size_t i = 2; i < items.size() - 1; i += 1) {
            deps_s[items[i + 1]] = {items[i], items[i - 1], items[i - 2]};
            deps_v[items[i + 1]] = {items[i], items[i - 1], items[i - 2]};
        }

        baphy::shuffle(items);

        // do the benchmark
}
```

The dependencies have to be kept as both `std::set` and `std::vector` since V1-3 and V7 use sets, but V4-6 use vectors.

The code for actually benchmarking the implementations:

```cpp
template<template<typename> typename T, typename IT, typename DT>
double benchmark(IT &items, DT &deps, const std::string &check_string) {
    auto sw = baphy::Stopwatch();
    auto pl = T<int>();
    for (const auto &[i, e]: baphy::enumerate(items))
        pl.add(e, deps[e], i);
    if (pl.debug_stringify() != check_string)
        MYCO_LOG_ERROR("Bad {} {}", pl.debug_stringify(), check_string);
    sw.stop();

    return sw.elapsed_sec();
}
```

Benchmarks are most fun with graphs!

![Comparison of V1-V7](/assets/img/mdii_full_comparison.png)

It's very hard to see V2-V6 with V1 and V7 being so much worse, so here's the graph without them:

![Comparison without V1 and V7](/assets/img/mdii_vector_comparison.png)

The changes made are as follows:
  
  - V2 -- aforementioned ID based changes
  - V3 -- mostly a cleanup of V2, but reducing number of function calls
  - V4 -- changed `std::set` to `std::vector`
  - V5 -- changed back to single vector to hold both names and values in a non-copyable struct
  - V6 -- changed `std::unordered_map` to `absl::flat_hash_map`

### Remarks

The nature of the method I chose requires inserting into a vector at essentially random locations. This is a known poor-performance operation, and appears to be the reason I cannot get the performance any lower. I did try some experiments--with code that no longer exists, unfortunately--using other structures like `std::deque`, and [segmented arrays](http://www.i42.co.uk/stuff/segmented_array.htm), but performance was even worse with anything I tried.

Realistically, for the purposes of the engine, there are not going to be more than 10-20 items in these lists, so the performance is negligible, I just wanted to more fully flesh out this idea into a workable system. I may revisit this sometime in the future with a totally different approach, but so far it's working great for handling the event bus subscriptions.

Speaking of the event bus, the `sub` method is implemented like so:

```cpp
template<typename T>
static void sub(const std::string &name, std::vector<std::string> &&deps, const Receiver<T> &&recv) {
    while (type_id<T> >= receivers_.size())
        receivers_.emplace_back();
    receivers_[type_id<T>].add(
            name,
            std::forward<std::vector<std::string>>(deps),
            std::make_unique<ReceiverWrap<T>>(std::forward<const Receiver<T>>(recv))
    );
}

template<typename T>
static void sub(const std::string &name, const Receiver<T> &&recv) {
    sub(name, {}, std::forward<const Receiver<T>>(recv));
}
```

This is very similar to the original implementation, there is just a way to specify dependencies. If you don't have any, the second overload will be used instead.